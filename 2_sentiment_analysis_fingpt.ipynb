{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a9cad5a",
   "metadata": {},
   "source": [
    "# FinGPT Sentiment Analysis & Price Forecasting\n",
    "\n",
    "This notebook uses:\n",
    "1. **FinGPT Sentiment** - For sentiment classification of financial news\n",
    "2. **FinGPT Forecaster** - For predicting actual price changes\n",
    "\n",
    "Both models run locally on your Mac (M-series with MPS acceleration).\n",
    "\n",
    "**Memory Optimized Version:** Models are loaded one at a time and unloaded after use to fit within 24GB RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cbf0349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "26/01/18 03:29:43 WARN Utils: Your hostname, Jeffreys-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 10.0.0.17 instead (on interface en0)\n",
      "26/01/18 03:29:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/18 03:29:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/01/18 03:29:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "26/01/18 03:29:44 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "26/01/18 03:29:44 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "# pyspark packages\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType\n",
    "\n",
    "#other needed packages\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Set JAVA_HOME for PySpark\n",
    "os.environ['JAVA_HOME'] = '/opt/homebrew/opt/openjdk@17'\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"stock market preds\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8810a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to import data, run SQL from file and save back to file\n",
    "def import_csv_to_table(table_name, file, format_cols):\n",
    "    df = spark.read.csv(file, header=True, quote=\"\\\"\",\n",
    "                        escape=\"\\\"\", multiLine=True, inferSchema=True)\n",
    "    if format_cols:\n",
    "        cols_formatted = [re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", col_name).lower().replace(\" \", \"_\") for col_name in df.columns]\n",
    "        df = df.toDF(*cols_formatted)\n",
    "    df.createOrReplaceTempView(f\"{table_name}\")\n",
    "    return df\n",
    "\n",
    "def sql_step(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        sql_text = f.read()\n",
    "    return spark.sql(sql_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "649ad0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = import_csv_to_table(\"news\", \"raw_data/news_data.csv\", False)\n",
    "stocks = import_csv_to_table(\"stocks\", \"raw_data/stock_data.csv\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd576f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------+\n",
      "|news_article_id|symbol|news_date |article_text                                                                                                                                                                                                                                                                                                                                                            |percent_daily_price_change|\n",
      "+---------------+------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------+\n",
      "|48346820       |LII   |2025-10-22|Headline: Earnings Scheduled For October 22, 2025 Summary:                                                                                                                                                                                                                                                                                                              |-0.013262810443220488     |\n",
      "|48346820       |SF    |2025-10-22|Headline: Earnings Scheduled For October 22, 2025 Summary:                                                                                                                                                                                                                                                                                                              |-5.084745762712057E-4     |\n",
      "|48931230       |VRT   |2025-11-18|Headline: 10 Industrials Stocks With Whale Alerts In Today's Session Summary:                                                                                                                                                                                                                                                                                           |-0.09784083201446968      |\n",
      "|47070626       |AAON  |2025-08-12|Headline: Mercury Systems Posts Better-Than-Expected Earnings, Joins Green Dot, Arcturus Therapeutics And Other Big Stocks Moving Higher On Tuesday Summary:                                                                                                                                                                                                            |-0.04195965417867436      |\n",
      "|49699047       |TSLA  |2026-01-05|Headline: EXCLUSIVE: Top 20 Most-Searched Tickers On Benzinga Pro In 2025 – Where Do Tesla, Nvidia, Palantir, Apple Stocks Rank? Summary: Benzinga Pro provides daily market news and stock information. SPY, TSLA, NVDA, PLTR, OPEN and AMD were the top searched stocks in first half of 2025.                                                                        |-0.010300527643954926     |\n",
      "|48191292       |GS    |2025-10-14|Headline: Earnings Scheduled For October 14, 2025 Summary:                                                                                                                                                                                                                                                                                                              |-0.016310694729193078     |\n",
      "|49031186       |ADC   |2025-11-24|Headline: Congressional Trading Report: Rep. Lisa McClain Sold Over $398K In Apple Stock Summary:                                                                                                                                                                                                                                                                       |0.0018666666666666742     |\n",
      "|48333748       |NDAQ  |2025-10-21|Headline: Gold Sinks 5% On Worst Day In 5 Years, Dow Jones Hits Record Highs: What's Moving Markets Tuesday? Summary: Gold prices suffered a sharp correction on Tuesday as investors locked in profits following this year&#39;s explosive rally, while optimism across earnings kept industrial stocks powering higher and pushed the Dow Jones to fresh record highs.|0.012193732193732116      |\n",
      "|49132138       |ZS    |2025-12-01|Headline: 5 Stock Picks Last Month From Wall Street's Most Accurate Analysts Summary:                                                                                                                                                                                                                                                                                   |0.012171312258546948      |\n",
      "|48615046       |CRUS  |2025-11-04|Headline: Earnings Scheduled For November 4, 2025 Summary:                                                                                                                                                                                                                                                                                                              |-0.011582368135988673     |\n",
      "+---------------+------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "feature_set = sql_step(\"sql/sentiment_data_prep_fingpt.sql\")\n",
    "feature_set.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a180932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "PyTorch version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "# Setup device (MPS for M-series Mac, CUDA for GPU, CPU as fallback)\n",
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89b93610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment functions defined.\n"
     ]
    }
   ],
   "source": [
    "# FinGPT Sentiment Scoring Function (model loaded on-demand)\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Updated to use available FinGPT models on Hugging Face\n",
    "# Using Llama2 7B version from oliverwang15 (the FinGPT author)\n",
    "BASE_MODEL = \"NousResearch/Llama-2-7b-hf\"\n",
    "SENTIMENT_ADAPTER = \"oliverwang15/FinGPT_v32_Llama2_Sentiment_Instruction_LoRA_FT\"\n",
    "\n",
    "def load_fingpt_sentiment():\n",
    "    \"\"\"Load FinGPT Sentiment model with CPU offloading for memory efficiency.\"\"\"\n",
    "    print(\"Loading FinGPT Sentiment model...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Use CPU for loading, then move to MPS for inference\n",
    "    # This prevents memory fragmentation issues\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        BASE_MODEL,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"mps\",  # Direct to MPS instead of auto\n",
    "        low_cpu_mem_usage=True,\n",
    "        offload_folder=\"offload\"  # Offload to disk if needed\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(model, SENTIMENT_ADAPTER)\n",
    "    model.eval()\n",
    "    print(\"FinGPT Sentiment model loaded successfully!\")\n",
    "    return tokenizer, model\n",
    "\n",
    "def unload_model(model, tokenizer):\n",
    "    \"\"\"Unload model and free memory.\"\"\"\n",
    "    del model\n",
    "    del tokenizer\n",
    "    gc.collect()\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch.mps.empty_cache()\n",
    "    elif torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"Model unloaded and memory freed.\")\n",
    "\n",
    "def score_sentiment_fingpt(article_text, tokenizer, model, max_length=512):\n",
    "    \"\"\"Score sentiment using FinGPT model.\"\"\"\n",
    "    prompt = f\"\"\"Instruction: What is the sentiment of this news? Please choose an answer from {{negative/neutral/positive}}.\n",
    "Input: {article_text[:500]}\n",
    "Answer: \"\"\"\n",
    "    \n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=10,\n",
    "                do_sample=False,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        answer = response.split(\"Answer:\")[-1].strip().lower()\n",
    "        \n",
    "        if \"positive\" in answer:\n",
    "            return \"positive\", 0.85\n",
    "        elif \"negative\" in answer:\n",
    "            return \"negative\", 0.85\n",
    "        else:\n",
    "            return \"neutral\", 0.7\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"neutral\", 0.5\n",
    "\n",
    "print(\"Sentiment functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e4e9dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to Hugging Face!\n"
     ]
    }
   ],
   "source": [
    "# Authenticate with Hugging Face using API key\n",
    "from huggingface_hub import login\n",
    "import json\n",
    "\n",
    "with open(\"api_keys.json\", \"r\") as f:\n",
    "    api_keys = json.load(f)\n",
    "\n",
    "login(token=api_keys[\"HUGGINGFACE_KEY\"])\n",
    "print(\"Successfully logged in to Hugging Face!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19c645d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles to score: 35430\n",
      "Loading FinGPT Sentiment model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:23<00:00, 41.59s/it]\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinGPT Sentiment model loaded successfully!\n",
      "Test: 'Goldman Sachs upgrades Apple to Buy rating with price target of $200'\n",
      "Sentiment: neutral, Confidence: 0.7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Sentiment:   1%|          | 184/35430 [04:24<14:05:25,  1.44s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m tqdm(df.iterrows(), total=\u001b[38;5;28mlen\u001b[39m(df), desc=\u001b[33m\"\u001b[39m\u001b[33mScoring Sentiment\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     20\u001b[39m     text = row[\u001b[33m'\u001b[39m\u001b[33marticle_text\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     sent, sent_conf = \u001b[43mscore_sentiment_fingpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_sentiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_sentiment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     sentiments.append(sent)\n\u001b[32m     23\u001b[39m     sentiment_confs.append(sent_conf)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mscore_sentiment_fingpt\u001b[39m\u001b[34m(article_text, tokenizer, model, max_length)\u001b[39m\n\u001b[32m     54\u001b[39m inputs = {k: v.to(model.device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs.items()}\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m response = tokenizer.decode(outputs[\u001b[32m0\u001b[39m], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     65\u001b[39m answer = response.split(\u001b[33m\"\u001b[39m\u001b[33mAnswer:\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m].strip().lower()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/stock_market_preds_v1/.venv3/lib/python3.13/site-packages/peft/peft_model.py:2048\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   2046\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   2047\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m2048\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2049\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2050\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/stock_market_preds_v1/.venv3/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/stock_market_preds_v1/.venv3/lib/python3.13/site-packages/transformers/generation/utils.py:2566\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2563\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2565\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2566\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2576\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2578\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2579\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2580\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2581\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/stock_market_preds_v1/.venv3/lib/python3.13/site-packages/transformers/generation/utils.py:2781\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2778\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2779\u001b[39m     is_prefill = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2781\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):\n\u001b[32m   2782\u001b[39m     \u001b[38;5;66;03m# prepare model inputs\u001b[39;00m\n\u001b[32m   2783\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(input_ids, **model_kwargs)\n\u001b[32m   2785\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# STEP 1: Score all articles with FinGPT Sentiment\n",
    "# Model is loaded, used, then unloaded to free memory\n",
    "\n",
    "df = feature_set.toPandas()\n",
    "print(f\"Total articles to score: {len(df)}\")\n",
    "\n",
    "# Load sentiment model\n",
    "tokenizer_sentiment, model_sentiment = load_fingpt_sentiment()\n",
    "\n",
    "# Test on a sample first\n",
    "test_text = \"Goldman Sachs upgrades Apple to Buy rating with price target of $200\"\n",
    "sentiment, conf = score_sentiment_fingpt(test_text, tokenizer_sentiment, model_sentiment)\n",
    "print(f\"Test: '{test_text}'\")\n",
    "print(f\"Sentiment: {sentiment}, Confidence: {conf}\\n\")\n",
    "\n",
    "# Score all articles\n",
    "sentiments, sentiment_confs = [], []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Scoring Sentiment\"):\n",
    "    text = row['article_text']\n",
    "    sent, sent_conf = score_sentiment_fingpt(text, tokenizer_sentiment, model_sentiment)\n",
    "    sentiments.append(sent)\n",
    "    sentiment_confs.append(sent_conf)\n",
    "\n",
    "df['sentiment'] = sentiments\n",
    "df['sentiment_confidence'] = sentiment_confs\n",
    "\n",
    "print(f\"\\nSentiment distribution:\\n{df['sentiment'].value_counts()}\")\n",
    "\n",
    "# Unload sentiment model to free memory for forecaster\n",
    "unload_model(model_sentiment, tokenizer_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c9e0d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory cleared!\n"
     ]
    }
   ],
   "source": [
    "# Clear memory from previous failed attempts\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Clear MPS cache\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "    \n",
    "print(\"Memory cleared!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc94af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FinGPT Forecaster Functions\n",
    "\n",
    "def load_fingpt_forecaster():\n",
    "    \"\"\"Load FinGPT Forecaster model.\"\"\"\n",
    "    print(\"Loading FinGPT Forecaster model...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        BASE_MODEL,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(model, FORECASTER_ADAPTER)\n",
    "    model.eval()\n",
    "    print(\"FinGPT Forecaster model loaded successfully!\")\n",
    "    return tokenizer, model\n",
    "\n",
    "def predict_price_change_fingpt(article_text, symbol, tokenizer, model, max_length=512):\n",
    "    \"\"\"Predict price direction using FinGPT Forecaster.\"\"\"\n",
    "    prompt = f\"\"\"Instruction: Based on the following news, predict if the stock price will go up, down, or stay stable. Answer with: up/down/stable.\n",
    "Company: {symbol}\n",
    "News: {article_text[:400]}\n",
    "Prediction: \"\"\"\n",
    "    \n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=15,\n",
    "                do_sample=False,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        answer = response.split(\"Prediction:\")[-1].strip().lower()\n",
    "        \n",
    "        if \"up\" in answer:\n",
    "            return \"up\", 0.7\n",
    "        elif \"down\" in answer:\n",
    "            return \"down\", 0.7\n",
    "        else:\n",
    "            return \"stable\", 0.6\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"stable\", 0.5\n",
    "\n",
    "print(\"Forecaster functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecac34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Predict price direction with FinGPT Forecaster\n",
    "# Sentiment model was unloaded, now load forecaster\n",
    "\n",
    "# Load forecaster model\n",
    "tokenizer_forecast, model_forecast = load_fingpt_forecaster()\n",
    "\n",
    "# Test on a sample first\n",
    "test_text = \"Apple reports record quarterly earnings beating analyst expectations\"\n",
    "direction, conf = predict_price_change_fingpt(test_text, \"AAPL\", tokenizer_forecast, model_forecast)\n",
    "print(f\"Test: '{test_text}'\")\n",
    "print(f\"Predicted direction: {direction}, Confidence: {conf}\\n\")\n",
    "\n",
    "# Predict for all articles\n",
    "predictions, prediction_confs = [], []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Predicting Price Direction\"):\n",
    "    text = row['article_text']\n",
    "    symbol = row['symbol']\n",
    "    pred, pred_conf = predict_price_change_fingpt(text, symbol, tokenizer_forecast, model_forecast)\n",
    "    predictions.append(pred)\n",
    "    prediction_confs.append(pred_conf)\n",
    "\n",
    "df['predicted_direction'] = predictions\n",
    "df['prediction_confidence'] = prediction_confs\n",
    "\n",
    "print(f\"\\nPrediction distribution:\\n{df['predicted_direction'].value_counts()}\")\n",
    "\n",
    "# Unload forecaster model to free memory\n",
    "unload_model(model_forecast, tokenizer_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff4b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd56470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results\n",
    "os.makedirs(\"processed_data\", exist_ok=True)\n",
    "df.to_csv(\"processed_data/fingpt_news_classifications.csv\", index=False)\n",
    "print(f\"Exported {len(df)} rows to processed_data/fingpt_news_classifications.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0671f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate FinGPT Performance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate actual direction\n",
    "df['actual_direction'] = df['percent_daily_price_change'].apply(\n",
    "    lambda x: 'up' if x > 0.005 else ('down' if x < -0.005 else 'stable')\n",
    ")\n",
    "\n",
    "# Binary accuracy (up/down only, excluding stable)\n",
    "df_binary = df[df['predicted_direction'] != 'stable'].copy()\n",
    "df_binary['actual_binary'] = df_binary['percent_daily_price_change'].apply(lambda x: 'up' if x > 0 else 'down')\n",
    "df_binary['correct'] = df_binary['predicted_direction'] == df_binary['actual_binary']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# 1. Sentiment Distribution\n",
    "sent_counts = df['sentiment'].value_counts()\n",
    "colors_sent = {'positive': 'green', 'neutral': 'gray', 'negative': 'red'}\n",
    "axes[0,0].bar(sent_counts.index, sent_counts.values, color=[colors_sent[s] for s in sent_counts.index])\n",
    "axes[0,0].set_title('FinGPT Sentiment Distribution')\n",
    "axes[0,0].set_ylabel('Count')\n",
    "\n",
    "# 2. Prediction Distribution\n",
    "pred_counts = df['predicted_direction'].value_counts()\n",
    "colors_pred = {'up': 'green', 'stable': 'gray', 'down': 'red'}\n",
    "axes[0,1].bar(pred_counts.index, pred_counts.values, color=[colors_pred.get(p, 'blue') for p in pred_counts.index])\n",
    "axes[0,1].set_title('FinGPT Price Prediction Distribution')\n",
    "axes[0,1].set_ylabel('Count')\n",
    "\n",
    "# 3. Actual vs Predicted\n",
    "actual_counts = df['actual_direction'].value_counts()\n",
    "x = np.arange(3)\n",
    "width = 0.35\n",
    "labels = ['up', 'stable', 'down']\n",
    "pred_vals = [pred_counts.get(l, 0) for l in labels]\n",
    "actual_vals = [actual_counts.get(l, 0) for l in labels]\n",
    "axes[0,2].bar(x - width/2, pred_vals, width, label='Predicted', alpha=0.7)\n",
    "axes[0,2].bar(x + width/2, actual_vals, width, label='Actual', alpha=0.7)\n",
    "axes[0,2].set_xticks(x)\n",
    "axes[0,2].set_xticklabels(labels)\n",
    "axes[0,2].set_title('Predicted vs Actual Distribution')\n",
    "axes[0,2].legend()\n",
    "\n",
    "# 4. Price Change by Sentiment\n",
    "means = df.groupby('sentiment')['percent_daily_price_change'].mean() * 100\n",
    "axes[1,0].bar(means.index, means.values, color=[colors_sent[s] for s in means.index])\n",
    "axes[1,0].set_title('Mean Price Change by Sentiment (%)')\n",
    "axes[1,0].axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 5. Prediction Accuracy by Direction\n",
    "if len(df_binary) > 0:\n",
    "    acc_by_pred = df_binary.groupby('predicted_direction')['correct'].mean() * 100\n",
    "    axes[1,1].bar(acc_by_pred.index, acc_by_pred.values, color=[colors_pred.get(p, 'blue') for p in acc_by_pred.index])\n",
    "    axes[1,1].axhline(50, color='red', linestyle='--', label='Random baseline')\n",
    "    axes[1,1].set_title('Prediction Accuracy by Direction (%)')\n",
    "    axes[1,1].legend()\n",
    "\n",
    "# 6. Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "if len(df_binary) > 0:\n",
    "    cm = confusion_matrix(df_binary['actual_binary'], df_binary['predicted_direction'], labels=['up', 'down'])\n",
    "    im = axes[1,2].imshow(cm, cmap='Blues')\n",
    "    axes[1,2].set_xticks([0, 1])\n",
    "    axes[1,2].set_yticks([0, 1])\n",
    "    axes[1,2].set_xticklabels(['Up', 'Down'])\n",
    "    axes[1,2].set_yticklabels(['Up', 'Down'])\n",
    "    axes[1,2].set_xlabel('Predicted')\n",
    "    axes[1,2].set_ylabel('Actual')\n",
    "    axes[1,2].set_title('Confusion Matrix')\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            axes[1,2].text(j, i, cm[i, j], ha='center', va='center', \n",
    "                          color='white' if cm[i, j] > cm.max()/2 else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary Statistics\n",
    "print(\"=\"*70)\n",
    "print(\"FINGPT PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal articles analyzed: {len(df)}\")\n",
    "print(f\"\\nSentiment Distribution:\")\n",
    "for s in ['positive', 'neutral', 'negative']:\n",
    "    count = len(df[df['sentiment'] == s])\n",
    "    pct = count / len(df) * 100\n",
    "    mean_change = df[df['sentiment'] == s]['percent_daily_price_change'].mean() * 100\n",
    "    print(f\"  {s:10}: {count:5} ({pct:5.1f}%) - Mean price change: {mean_change:+.3f}%\")\n",
    "\n",
    "print(f\"\\nPrediction Accuracy (up/down only):\")\n",
    "if len(df_binary) > 0:\n",
    "    overall_acc = df_binary['correct'].mean() * 100\n",
    "    print(f\"  Overall: {overall_acc:.1f}%\")\n",
    "    for pred in ['up', 'down']:\n",
    "        subset = df_binary[df_binary['predicted_direction'] == pred]\n",
    "        if len(subset) > 0:\n",
    "            acc = subset['correct'].mean() * 100\n",
    "            print(f\"  {pred:10}: {acc:.1f}% ({len(subset)} predictions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de50182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Sentiment vs Forecaster accuracy\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SENTIMENT vs FORECASTER COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sentiment-based direction\n",
    "df['sentiment_direction'] = df['sentiment'].map({'positive': 'up', 'negative': 'down', 'neutral': 'stable'})\n",
    "df_sent_binary = df[df['sentiment'] != 'neutral'].copy()\n",
    "df_sent_binary['actual_binary'] = df_sent_binary['percent_daily_price_change'].apply(lambda x: 'up' if x > 0 else 'down')\n",
    "df_sent_binary['sent_correct'] = df_sent_binary['sentiment_direction'] == df_sent_binary['actual_binary']\n",
    "\n",
    "print(f\"\\nSentiment-based accuracy (pos/neg → up/down): {df_sent_binary['sent_correct'].mean()*100:.1f}%\")\n",
    "if len(df_binary) > 0:\n",
    "    print(f\"Forecaster accuracy (up/down predictions):     {df_binary['correct'].mean()*100:.1f}%\")\n",
    "\n",
    "print(\"\\nNote: If both are around 50%, news sentiment may not strongly predict next-day returns.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
