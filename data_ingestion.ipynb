{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5978785",
   "metadata": {},
   "source": [
    "# First, assign Alpaca API Keys from untracked file and test connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f93437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('api_keys.json', 'r') as file:\n",
    "    # Code to load the data goes here\n",
    "    api_keys = json.load(file)\n",
    "\n",
    "API_KEY = api_keys['API_KEY']\n",
    "SECRET_KEY = api_keys['SECRET_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e013e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpaca.data.historical import CryptoHistoricalDataClient\n",
    "\n",
    "# No keys required for crypto data\n",
    "client = CryptoHistoricalDataClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dfd2d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpaca.data.requests import CryptoBarsRequest\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from datetime import datetime\n",
    "\n",
    "# Creating request object\n",
    "request_params = CryptoBarsRequest(\n",
    "  symbol_or_symbols=[\"BTC/USD\"],\n",
    "  timeframe=TimeFrame.Day,\n",
    "  start=datetime(2022, 9, 1),\n",
    "  end=datetime(2022, 9, 7)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d89846c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">BTC/USD</th>\n",
       "      <th>2022-09-01 00:00:00+00:00</th>\n",
       "      <td>20051.81</td>\n",
       "      <td>20205.83</td>\n",
       "      <td>19564.86</td>\n",
       "      <td>20132.97</td>\n",
       "      <td>7529.674053</td>\n",
       "      <td>114052.0</td>\n",
       "      <td>19934.701556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02 00:00:00+00:00</th>\n",
       "      <td>20132.50</td>\n",
       "      <td>20444.00</td>\n",
       "      <td>19757.72</td>\n",
       "      <td>19954.16</td>\n",
       "      <td>7392.679014</td>\n",
       "      <td>98745.0</td>\n",
       "      <td>20095.899441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-03 00:00:00+00:00</th>\n",
       "      <td>19950.63</td>\n",
       "      <td>20054.69</td>\n",
       "      <td>19658.04</td>\n",
       "      <td>19832.06</td>\n",
       "      <td>3077.135497</td>\n",
       "      <td>52729.0</td>\n",
       "      <td>19839.406563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-04 00:00:00+00:00</th>\n",
       "      <td>19834.87</td>\n",
       "      <td>20030.89</td>\n",
       "      <td>19587.86</td>\n",
       "      <td>20002.38</td>\n",
       "      <td>3712.178165</td>\n",
       "      <td>60722.0</td>\n",
       "      <td>19813.537532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05 00:00:00+00:00</th>\n",
       "      <td>19998.77</td>\n",
       "      <td>20058.00</td>\n",
       "      <td>19635.96</td>\n",
       "      <td>19795.12</td>\n",
       "      <td>4817.489036</td>\n",
       "      <td>66396.0</td>\n",
       "      <td>19801.578592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-06 00:00:00+00:00</th>\n",
       "      <td>19795.12</td>\n",
       "      <td>20180.50</td>\n",
       "      <td>18668.90</td>\n",
       "      <td>18790.39</td>\n",
       "      <td>11753.830278</td>\n",
       "      <td>139147.0</td>\n",
       "      <td>19480.986370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07 00:00:00+00:00</th>\n",
       "      <td>18789.40</td>\n",
       "      <td>19462.02</td>\n",
       "      <td>18534.06</td>\n",
       "      <td>19290.53</td>\n",
       "      <td>8092.183326</td>\n",
       "      <td>89704.0</td>\n",
       "      <td>18952.481132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       open      high       low     close  \\\n",
       "symbol  timestamp                                                           \n",
       "BTC/USD 2022-09-01 00:00:00+00:00  20051.81  20205.83  19564.86  20132.97   \n",
       "        2022-09-02 00:00:00+00:00  20132.50  20444.00  19757.72  19954.16   \n",
       "        2022-09-03 00:00:00+00:00  19950.63  20054.69  19658.04  19832.06   \n",
       "        2022-09-04 00:00:00+00:00  19834.87  20030.89  19587.86  20002.38   \n",
       "        2022-09-05 00:00:00+00:00  19998.77  20058.00  19635.96  19795.12   \n",
       "        2022-09-06 00:00:00+00:00  19795.12  20180.50  18668.90  18790.39   \n",
       "        2022-09-07 00:00:00+00:00  18789.40  19462.02  18534.06  19290.53   \n",
       "\n",
       "                                         volume  trade_count          vwap  \n",
       "symbol  timestamp                                                           \n",
       "BTC/USD 2022-09-01 00:00:00+00:00   7529.674053     114052.0  19934.701556  \n",
       "        2022-09-02 00:00:00+00:00   7392.679014      98745.0  20095.899441  \n",
       "        2022-09-03 00:00:00+00:00   3077.135497      52729.0  19839.406563  \n",
       "        2022-09-04 00:00:00+00:00   3712.178165      60722.0  19813.537532  \n",
       "        2022-09-05 00:00:00+00:00   4817.489036      66396.0  19801.578592  \n",
       "        2022-09-06 00:00:00+00:00  11753.830278     139147.0  19480.986370  \n",
       "        2022-09-07 00:00:00+00:00   8092.183326      89704.0  18952.481132  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve daily bars for Bitcoin in a DataFrame and printing it\n",
    "btc_bars = client.get_crypto_bars(request_params)\n",
    "\n",
    "# Convert to dataframe\n",
    "btc_bars.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d3666",
   "metadata": {},
   "source": [
    "# After testing if it works, import all historical stock symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a38876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ S&P 500: 503 symbols\n",
      "✓ Russell 1000 (iShares IWB): 1012 symbols\n",
      "\n",
      "==================================================\n",
      "Total unique symbols: 1019\n",
      "First 20 symbols: ['A', 'AA', 'AAL', 'AAON', 'AAPL', 'ABBV', 'ABNB', 'ABT', 'ACGL', 'ACHC', 'ACI', 'ACM', 'ACN', 'ADBE', 'ADC', 'ADI', 'ADM', 'ADP', 'ADSK', 'ADT']\n",
      "\n",
      "Full list available in SYMBOLS variable\n",
      "✓ Russell 1000 (iShares IWB): 1012 symbols\n",
      "\n",
      "==================================================\n",
      "Total unique symbols: 1019\n",
      "First 20 symbols: ['A', 'AA', 'AAL', 'AAON', 'AAPL', 'ABBV', 'ABNB', 'ABT', 'ACGL', 'ACHC', 'ACI', 'ACM', 'ACN', 'ADBE', 'ADC', 'ADI', 'ADM', 'ADP', 'ADSK', 'ADT']\n",
      "\n",
      "Full list available in SYMBOLS variable\n"
     ]
    }
   ],
   "source": [
    "# Fetch S&P 500 + Russell 1000 stock symbols\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "\n",
    "all_symbols = set()\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "# 1. S&P 500 from Wikipedia\n",
    "try:\n",
    "    sp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    response = requests.get(sp500_url, headers=headers)\n",
    "    sp500_tables = pd.read_html(io.StringIO(response.text))\n",
    "    sp500_symbols = sp500_tables[0]['Symbol'].str.replace('.', '-', regex=False).tolist()\n",
    "    all_symbols.update(sp500_symbols)\n",
    "    print(f\"✓ S&P 500: {len(sp500_symbols)} symbols\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ S&P 500 failed: {e}\")\n",
    "\n",
    "# 2. Russell 1000 from iShares IWB ETF holdings (tracks Russell 1000)\n",
    "try:\n",
    "    # iShares Russell 1000 ETF holdings CSV\n",
    "    iwb_url = \"https://www.ishares.com/us/products/239707/ishares-russell-1000-etf/1467271812596.ajax?fileType=csv&fileName=IWB_holdings&dataType=fund\"\n",
    "    response = requests.get(iwb_url, headers=headers)\n",
    "    \n",
    "    # Skip the header rows and read the CSV\n",
    "    lines = response.text.split('\\n')\n",
    "    # Find where the actual data starts (after header info)\n",
    "    start_idx = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith('Ticker,'):\n",
    "            start_idx = i\n",
    "            break\n",
    "    \n",
    "    csv_data = '\\n'.join(lines[start_idx:])\n",
    "    russell_df = pd.read_csv(io.StringIO(csv_data))\n",
    "    \n",
    "    if 'Ticker' in russell_df.columns:\n",
    "        russell_symbols = russell_df['Ticker'].dropna().str.strip().tolist()\n",
    "        # Filter out non-stock entries (like cash, futures, etc.)\n",
    "        russell_symbols = [s for s in russell_symbols if s and s.isalpha() and len(s) <= 5]\n",
    "        all_symbols.update(russell_symbols)\n",
    "        print(f\"✓ Russell 1000 (iShares IWB): {len(russell_symbols)} symbols\")\n",
    "    else:\n",
    "        print(f\"✗ Russell 1000: Ticker column not found. Columns: {russell_df.columns.tolist()}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Russell 1000 failed: {e}\")\n",
    "    print(\"  Falling back to S&P 500 only\")\n",
    "\n",
    "# Convert to sorted list\n",
    "SYMBOLS = sorted([s for s in all_symbols if s and isinstance(s, str)])\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Total unique symbols: {len(SYMBOLS)}\")\n",
    "print(f\"First 20 symbols: {SYMBOLS[:20]}\")\n",
    "print(f\"\\nFull list available in SYMBOLS variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca28fa5d",
   "metadata": {},
   "source": [
    "# Next, use symbols Import historical Russell 1000 stock data from alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ecd2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 1019 symbols...\n",
      "Date range: 2025-01-07 to 2026-01-07\n",
      "\n",
      "Progress: 50/1019 symbols fetched...\n",
      "Progress: 50/1019 symbols fetched...\n",
      "Progress: 100/1019 symbols fetched...\n",
      "Progress: 100/1019 symbols fetched...\n",
      "  ✗ Error fetching BF-B: {\"message\":\"invalid symbol: BF-B\"}\n",
      "\n",
      "  ✗ Error fetching BF-B: {\"message\":\"invalid symbol: BF-B\"}\n",
      "\n",
      "  ✗ Error fetching BRK-B: {\"message\":\"invalid symbol: BRK-B\"}\n",
      "\n",
      "  ✗ Error fetching BRK-B: {\"message\":\"invalid symbol: BRK-B\"}\n",
      "\n",
      "Progress: 150/1019 symbols fetched...\n",
      "Progress: 150/1019 symbols fetched...\n",
      "Progress: 200/1019 symbols fetched...\n",
      "Progress: 200/1019 symbols fetched...\n",
      "Progress: 250/1019 symbols fetched...\n",
      "Progress: 250/1019 symbols fetched...\n",
      "Progress: 300/1019 symbols fetched...\n",
      "Progress: 300/1019 symbols fetched...\n",
      "Progress: 350/1019 symbols fetched...\n",
      "Progress: 350/1019 symbols fetched...\n",
      "Progress: 400/1019 symbols fetched...\n",
      "Progress: 400/1019 symbols fetched...\n",
      "Progress: 450/1019 symbols fetched...\n",
      "Progress: 450/1019 symbols fetched...\n",
      "Progress: 500/1019 symbols fetched...\n",
      "Progress: 500/1019 symbols fetched...\n",
      "Progress: 550/1019 symbols fetched...\n",
      "Progress: 550/1019 symbols fetched...\n",
      "Progress: 600/1019 symbols fetched...\n",
      "Progress: 600/1019 symbols fetched...\n",
      "Progress: 650/1019 symbols fetched...\n",
      "Progress: 650/1019 symbols fetched...\n",
      "Progress: 700/1019 symbols fetched...\n",
      "Progress: 700/1019 symbols fetched...\n",
      "Progress: 750/1019 symbols fetched...\n",
      "Progress: 750/1019 symbols fetched...\n",
      "Progress: 800/1019 symbols fetched...\n",
      "Progress: 800/1019 symbols fetched...\n",
      "Progress: 850/1019 symbols fetched...\n",
      "Progress: 850/1019 symbols fetched...\n",
      "Progress: 900/1019 symbols fetched...\n",
      "Progress: 900/1019 symbols fetched...\n",
      "Progress: 950/1019 symbols fetched...\n",
      "Progress: 950/1019 symbols fetched...\n",
      "Progress: 1000/1019 symbols fetched...\n",
      "Progress: 1000/1019 symbols fetched...\n",
      "\n",
      "==================================================\n",
      "✓ Successfully fetched 250167 data points for 1017 stocks\n",
      "✗ Failed to fetch 2 symbols: ['BF-B', 'BRK-B']\n",
      "\n",
      "Combined DataFrame shape: (250167, 10)\n",
      "\n",
      "Combined DataFrame preview:\n",
      "\n",
      "==================================================\n",
      "✓ Successfully fetched 250167 data points for 1017 stocks\n",
      "✗ Failed to fetch 2 symbols: ['BF-B', 'BRK-B']\n",
      "\n",
      "Combined DataFrame shape: (250167, 10)\n",
      "\n",
      "Combined DataFrame preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-01-08 05:00:00+00:00</td>\n",
       "      <td>137.68</td>\n",
       "      <td>137.680</td>\n",
       "      <td>135.630</td>\n",
       "      <td>137.00</td>\n",
       "      <td>1684573.0</td>\n",
       "      <td>19948.0</td>\n",
       "      <td>137.068421</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-01-10 05:00:00+00:00</td>\n",
       "      <td>134.75</td>\n",
       "      <td>140.140</td>\n",
       "      <td>134.709</td>\n",
       "      <td>137.47</td>\n",
       "      <td>1369875.0</td>\n",
       "      <td>25383.0</td>\n",
       "      <td>137.592663</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-01-13 05:00:00+00:00</td>\n",
       "      <td>137.22</td>\n",
       "      <td>142.820</td>\n",
       "      <td>137.000</td>\n",
       "      <td>141.95</td>\n",
       "      <td>1561959.0</td>\n",
       "      <td>28739.0</td>\n",
       "      <td>141.776934</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-01-14 05:00:00+00:00</td>\n",
       "      <td>142.00</td>\n",
       "      <td>145.380</td>\n",
       "      <td>140.150</td>\n",
       "      <td>143.43</td>\n",
       "      <td>2445434.0</td>\n",
       "      <td>36636.0</td>\n",
       "      <td>143.373405</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-01-15 05:00:00+00:00</td>\n",
       "      <td>144.14</td>\n",
       "      <td>146.500</td>\n",
       "      <td>138.680</td>\n",
       "      <td>142.23</td>\n",
       "      <td>2328643.0</td>\n",
       "      <td>35076.0</td>\n",
       "      <td>142.841548</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-01-16 05:00:00+00:00</td>\n",
       "      <td>142.78</td>\n",
       "      <td>145.110</td>\n",
       "      <td>140.430</td>\n",
       "      <td>144.72</td>\n",
       "      <td>1661474.0</td>\n",
       "      <td>25916.0</td>\n",
       "      <td>143.989713</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-01-17 05:00:00+00:00</td>\n",
       "      <td>145.88</td>\n",
       "      <td>148.460</td>\n",
       "      <td>145.195</td>\n",
       "      <td>147.36</td>\n",
       "      <td>3210310.0</td>\n",
       "      <td>45636.0</td>\n",
       "      <td>147.281027</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-01-21 05:00:00+00:00</td>\n",
       "      <td>148.67</td>\n",
       "      <td>153.180</td>\n",
       "      <td>148.010</td>\n",
       "      <td>152.57</td>\n",
       "      <td>2759636.0</td>\n",
       "      <td>42383.0</td>\n",
       "      <td>152.146760</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-01-22 05:00:00+00:00</td>\n",
       "      <td>152.83</td>\n",
       "      <td>153.760</td>\n",
       "      <td>151.720</td>\n",
       "      <td>152.60</td>\n",
       "      <td>1730996.0</td>\n",
       "      <td>27740.0</td>\n",
       "      <td>152.631508</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-01-23 05:00:00+00:00</td>\n",
       "      <td>152.83</td>\n",
       "      <td>152.955</td>\n",
       "      <td>148.180</td>\n",
       "      <td>152.45</td>\n",
       "      <td>1332235.0</td>\n",
       "      <td>24444.0</td>\n",
       "      <td>151.813582</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                 timestamp    open     high      low   close  \\\n",
       "0      A 2025-01-08 05:00:00+00:00  137.68  137.680  135.630  137.00   \n",
       "1      A 2025-01-10 05:00:00+00:00  134.75  140.140  134.709  137.47   \n",
       "2      A 2025-01-13 05:00:00+00:00  137.22  142.820  137.000  141.95   \n",
       "3      A 2025-01-14 05:00:00+00:00  142.00  145.380  140.150  143.43   \n",
       "4      A 2025-01-15 05:00:00+00:00  144.14  146.500  138.680  142.23   \n",
       "5      A 2025-01-16 05:00:00+00:00  142.78  145.110  140.430  144.72   \n",
       "6      A 2025-01-17 05:00:00+00:00  145.88  148.460  145.195  147.36   \n",
       "7      A 2025-01-21 05:00:00+00:00  148.67  153.180  148.010  152.57   \n",
       "8      A 2025-01-22 05:00:00+00:00  152.83  153.760  151.720  152.60   \n",
       "9      A 2025-01-23 05:00:00+00:00  152.83  152.955  148.180  152.45   \n",
       "\n",
       "      volume  trade_count        vwap  index  \n",
       "0  1684573.0      19948.0  137.068421    NaN  \n",
       "1  1369875.0      25383.0  137.592663    NaN  \n",
       "2  1561959.0      28739.0  141.776934    NaN  \n",
       "3  2445434.0      36636.0  143.373405    NaN  \n",
       "4  2328643.0      35076.0  142.841548    NaN  \n",
       "5  1661474.0      25916.0  143.989713    NaN  \n",
       "6  3210310.0      45636.0  147.281027    NaN  \n",
       "7  2759636.0      42383.0  152.146760    NaN  \n",
       "8  1730996.0      27740.0  152.631508    NaN  \n",
       "9  1332235.0      24444.0  151.813582    NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from alpaca.data.historical import StockHistoricalDataClient\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import time\n",
    "\n",
    "# SYMBOLS is defined in the previous cell (S&P 500 list)\n",
    "# Uncomment below to use a smaller test set:\n",
    "# SYMBOLS = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\"]\n",
    "\n",
    "# 1. Initialize the client\n",
    "stock_client = StockHistoricalDataClient(API_KEY, SECRET_KEY)\n",
    "\n",
    "# 2. Define the date range for the last year\n",
    "end_date = datetime.now(pytz.timezone('America/New_York')) - timedelta(days=1)\n",
    "start_date = end_date - timedelta(days=365)\n",
    "\n",
    "# 3. Dictionary to store all DataFrames\n",
    "all_stock_data = {}\n",
    "failed_symbols = []\n",
    "\n",
    "# 4. Iterate through each symbol and fetch data\n",
    "print(f\"Fetching data for {len(SYMBOLS)} symbols...\")\n",
    "print(f\"Date range: {start_date.date()} to {end_date.date()}\\n\")\n",
    "\n",
    "for i, symbol in enumerate(SYMBOLS):\n",
    "    try:\n",
    "        request_params = StockBarsRequest(\n",
    "            symbol_or_symbols=[symbol],\n",
    "            timeframe=TimeFrame.Day,\n",
    "            start=start_date,\n",
    "            end=end_date\n",
    "        )\n",
    "        \n",
    "        stock_bars = stock_client.get_stock_bars(request_params)\n",
    "        bars_df = stock_bars.df\n",
    "        \n",
    "        # Reset index to make symbol a column instead of multi-index\n",
    "        bars_df = bars_df.reset_index()\n",
    "        \n",
    "        all_stock_data[symbol] = bars_df\n",
    "        \n",
    "        # Progress update every 50 symbols\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Progress: {i + 1}/{len(SYMBOLS)} symbols fetched...\")\n",
    "        \n",
    "        # Small delay to avoid rate limiting\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        failed_symbols.append(symbol)\n",
    "        print(f\"  ✗ Error fetching {symbol}: {e}\")\n",
    "\n",
    "# 5. Combine all DataFrames into one\n",
    "if all_stock_data:\n",
    "    combined_df = pd.concat(all_stock_data.values(), ignore_index=True)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"✓ Successfully fetched {len(combined_df)} data points for {len(all_stock_data)} stocks\")\n",
    "    if failed_symbols:\n",
    "        print(f\"✗ Failed to fetch {len(failed_symbols)} symbols: {failed_symbols[:10]}{'...' if len(failed_symbols) > 10 else ''}\")\n",
    "    print(f\"\\nCombined DataFrame shape: {combined_df.shape}\")\n",
    "    print(f\"\\nCombined DataFrame preview:\")\n",
    "    display(combined_df.head(10))\n",
    "else:\n",
    "    print(\"No data was fetched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b44cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data saved to stock_data.csv\n",
      "  File size: 20.36 MB\n"
     ]
    }
   ],
   "source": [
    "# Save the combined DataFrame to CSV\n",
    "import os\n",
    "\n",
    "output_file = \"stock_data.csv\"\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "print(f\"✓ Data saved to {output_file}\")\n",
    "print(f\"  File size: {os.path.getsize(output_file) / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a2a991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tickers saved to tickers.csv\n",
      "  Total tickers: 1019\n"
     ]
    }
   ],
   "source": [
    "# Save the list of tickers to CSV\n",
    "tickers_df = pd.DataFrame({'symbol': SYMBOLS})\n",
    "tickers_file = \"tickers.csv\"\n",
    "tickers_df.to_csv(tickers_file, index=False)\n",
    "print(f\"✓ Tickers saved to {tickers_file}\")\n",
    "print(f\"  Total tickers: {len(SYMBOLS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccab0d8a",
   "metadata": {},
   "source": [
    "# Next import historical financial statement data from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2717ca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching financials for 1019 symbols...\n",
      "This may take a while...\n",
      "\n",
      "Progress: 50/1019 symbols fetched...\n",
      "Progress: 50/1019 symbols fetched...\n",
      "Progress: 100/1019 symbols fetched...\n",
      "Progress: 100/1019 symbols fetched...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BFA: No earnings dates found, symbol may be delisted\n",
      "BFB: No earnings dates found, symbol may be delisted\n",
      "BFB: No earnings dates found, symbol may be delisted\n",
      "BRKB: No earnings dates found, symbol may be delisted\n",
      "BRKB: No earnings dates found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 150/1019 symbols fetched...\n",
      "Progress: 200/1019 symbols fetched...\n",
      "Progress: 200/1019 symbols fetched...\n",
      "Progress: 250/1019 symbols fetched...\n",
      "Progress: 250/1019 symbols fetched...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CWENA: No earnings dates found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 300/1019 symbols fetched...\n",
      "Progress: 350/1019 symbols fetched...\n",
      "Progress: 350/1019 symbols fetched...\n",
      "Progress: 400/1019 symbols fetched...\n",
      "Progress: 400/1019 symbols fetched...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HEIA: No earnings dates found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 450/1019 symbols fetched...\n",
      "Progress: 500/1019 symbols fetched...\n",
      "Progress: 500/1019 symbols fetched...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LENB: No earnings dates found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 550/1019 symbols fetched...\n",
      "Progress: 600/1019 symbols fetched...\n",
      "Progress: 600/1019 symbols fetched...\n",
      "Progress: 650/1019 symbols fetched...\n",
      "Progress: 650/1019 symbols fetched...\n",
      "Progress: 700/1019 symbols fetched...\n",
      "Progress: 700/1019 symbols fetched...\n",
      "Progress: 750/1019 symbols fetched...\n",
      "Progress: 750/1019 symbols fetched...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REXR: No earnings dates found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 800/1019 symbols fetched...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SGAFT: No earnings dates found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 850/1019 symbols fetched...\n",
      "Progress: 900/1019 symbols fetched...\n",
      "Progress: 900/1019 symbols fetched...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UHALB: No earnings dates found, symbol may be delisted\n",
      "USD: No earnings dates found, symbol may be delisted\n",
      "USD: No earnings dates found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 950/1019 symbols fetched...\n",
      "Progress: 1000/1019 symbols fetched...\n",
      "Progress: 1000/1019 symbols fetched...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XTSLA: No earnings dates found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "✓ Income Statement: 4165 rows, 1008 stocks\n",
      "✓ Balance Sheet: 4201 rows, 1008 stocks\n",
      "✓ Cash Flow: 4209 rows, 1008 stocks\n",
      "✓ Earnings Dates: 23789 rows, 1008 stocks\n",
      "\n",
      "Earnings Release Dates preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>release_date</th>\n",
       "      <th>EPS Estimate</th>\n",
       "      <th>Reported EPS</th>\n",
       "      <th>Surprise(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2026-02-25 16:00:00-05:00</td>\n",
       "      <td>1.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-11-24 16:00:00-05:00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-08-27 16:00:00-04:00</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-05-28 16:00:00-04:00</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.31</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-02-26 16:00:00-05:00</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>2024-11-25 16:00:00-05:00</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>2024-08-21 16:00:00-04:00</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>4.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>2024-05-29 16:00:00-04:00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>2024-02-27 16:00:00-05:00</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>2023-11-20 16:00:00-05:00</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.38</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol              release_date  EPS Estimate  Reported EPS  Surprise(%)\n",
       "0      A 2026-02-25 16:00:00-05:00          1.37           NaN          NaN\n",
       "1      A 2025-11-24 16:00:00-05:00          1.58          1.59         0.37\n",
       "2      A 2025-08-27 16:00:00-04:00          1.37          1.37         0.17\n",
       "3      A 2025-05-28 16:00:00-04:00          1.26          1.31         3.62\n",
       "4      A 2025-02-26 16:00:00-05:00          1.27          1.31         2.99\n",
       "5      A 2024-11-25 16:00:00-05:00          1.41          1.46         3.90\n",
       "6      A 2024-08-21 16:00:00-04:00          1.26          1.32         4.93\n",
       "7      A 2024-05-29 16:00:00-04:00          1.19          1.22         2.42\n",
       "8      A 2024-02-27 16:00:00-05:00          1.23          1.29         4.68\n",
       "9      A 2023-11-20 16:00:00-05:00          1.34          1.38         3.02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Income Statement preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>fiscal_period_end</th>\n",
       "      <th>Tax Effect Of Unusual Items</th>\n",
       "      <th>Tax Rate For Calcs</th>\n",
       "      <th>Normalized EBITDA</th>\n",
       "      <th>Net Income From Continuing Operation Net Minority Interest</th>\n",
       "      <th>Reconciled Depreciation</th>\n",
       "      <th>Reconciled Cost Of Revenue</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>...</th>\n",
       "      <th>Other Taxes</th>\n",
       "      <th>Provision For Doubtful Accounts</th>\n",
       "      <th>Other Non Interest Expense</th>\n",
       "      <th>Occupancy And Equipment</th>\n",
       "      <th>Professional Expense And Contract Services Expense</th>\n",
       "      <th>Excise Taxes</th>\n",
       "      <th>Depletion Income Statement</th>\n",
       "      <th>Net Income From Tax Loss Carryforward</th>\n",
       "      <th>Net Income Extraordinary</th>\n",
       "      <th>Securities Amortization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092</td>\n",
       "      <td>1.835000e+09</td>\n",
       "      <td>1.303000e+09</td>\n",
       "      <td>288000000.0</td>\n",
       "      <td>3.305000e+09</td>\n",
       "      <td>1.835000e+09</td>\n",
       "      <td>1.547000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153</td>\n",
       "      <td>1.874000e+09</td>\n",
       "      <td>1.289000e+09</td>\n",
       "      <td>257000000.0</td>\n",
       "      <td>2.975000e+09</td>\n",
       "      <td>1.874000e+09</td>\n",
       "      <td>1.617000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074</td>\n",
       "      <td>1.705000e+09</td>\n",
       "      <td>1.240000e+09</td>\n",
       "      <td>271000000.0</td>\n",
       "      <td>3.368000e+09</td>\n",
       "      <td>1.705000e+09</td>\n",
       "      <td>1.434000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>1.905000e+09</td>\n",
       "      <td>1.254000e+09</td>\n",
       "      <td>317000000.0</td>\n",
       "      <td>3.126000e+09</td>\n",
       "      <td>1.905000e+09</td>\n",
       "      <td>1.588000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol fiscal_period_end  Tax Effect Of Unusual Items  Tax Rate For Calcs  \\\n",
       "0      A        2025-10-31                          0.0               0.092   \n",
       "1      A        2024-10-31                          0.0               0.153   \n",
       "2      A        2023-10-31                          0.0               0.074   \n",
       "3      A        2022-10-31                          0.0               0.166   \n",
       "4      A        2021-10-31                          NaN                 NaN   \n",
       "\n",
       "   Normalized EBITDA  \\\n",
       "0       1.835000e+09   \n",
       "1       1.874000e+09   \n",
       "2       1.705000e+09   \n",
       "3       1.905000e+09   \n",
       "4                NaN   \n",
       "\n",
       "   Net Income From Continuing Operation Net Minority Interest  \\\n",
       "0                                       1.303000e+09            \n",
       "1                                       1.289000e+09            \n",
       "2                                       1.240000e+09            \n",
       "3                                       1.254000e+09            \n",
       "4                                                NaN            \n",
       "\n",
       "   Reconciled Depreciation  Reconciled Cost Of Revenue        EBITDA  \\\n",
       "0              288000000.0                3.305000e+09  1.835000e+09   \n",
       "1              257000000.0                2.975000e+09  1.874000e+09   \n",
       "2              271000000.0                3.368000e+09  1.705000e+09   \n",
       "3              317000000.0                3.126000e+09  1.905000e+09   \n",
       "4                      NaN                         NaN           NaN   \n",
       "\n",
       "           EBIT  ...  Other Taxes  Provision For Doubtful Accounts  \\\n",
       "0  1.547000e+09  ...          NaN                              NaN   \n",
       "1  1.617000e+09  ...          NaN                              NaN   \n",
       "2  1.434000e+09  ...          NaN                              NaN   \n",
       "3  1.588000e+09  ...          NaN                              NaN   \n",
       "4           NaN  ...          NaN                              NaN   \n",
       "\n",
       "   Other Non Interest Expense  Occupancy And Equipment  \\\n",
       "0                         NaN                      NaN   \n",
       "1                         NaN                      NaN   \n",
       "2                         NaN                      NaN   \n",
       "3                         NaN                      NaN   \n",
       "4                         NaN                      NaN   \n",
       "\n",
       "   Professional Expense And Contract Services Expense  Excise Taxes  \\\n",
       "0                                                NaN            NaN   \n",
       "1                                                NaN            NaN   \n",
       "2                                                NaN            NaN   \n",
       "3                                                NaN            NaN   \n",
       "4                                                NaN            NaN   \n",
       "\n",
       "   Depletion Income Statement  Net Income From Tax Loss Carryforward  \\\n",
       "0                         NaN                                    NaN   \n",
       "1                         NaN                                    NaN   \n",
       "2                         NaN                                    NaN   \n",
       "3                         NaN                                    NaN   \n",
       "4                         NaN                                    NaN   \n",
       "\n",
       "   Net Income Extraordinary  Securities Amortization  \n",
       "0                       NaN                      NaN  \n",
       "1                       NaN                      NaN  \n",
       "2                       NaN                      NaN  \n",
       "3                       NaN                      NaN  \n",
       "4                       NaN                      NaN  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch historical financials from Yahoo Finance\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Load tickers from CSV (or use SYMBOLS if already in memory)\n",
    "tickers_df = pd.read_csv(\"tickers.csv\")\n",
    "symbols = tickers_df['symbol'].tolist()\n",
    "\n",
    "# Lists to store financials data\n",
    "all_income_stmt = []\n",
    "all_balance_sheet = []\n",
    "all_cashflow = []\n",
    "all_earnings_dates = []\n",
    "failed_financials = []\n",
    "\n",
    "print(f\"Fetching financials for {len(symbols)} symbols...\")\n",
    "print(\"This may take a while...\\n\")\n",
    "\n",
    "for i, symbol in enumerate(symbols):\n",
    "    try:\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        \n",
    "        # Get annual financials (income statement, balance sheet, cash flow)\n",
    "        income_stmt = ticker.income_stmt\n",
    "        balance_sheet = ticker.balance_sheet\n",
    "        cashflow = ticker.cashflow\n",
    "        \n",
    "        # Get earnings release dates (historical and upcoming)\n",
    "        try:\n",
    "            earnings_dates = ticker.earnings_dates\n",
    "            if earnings_dates is not None and not earnings_dates.empty:\n",
    "                earnings_df = earnings_dates.reset_index()\n",
    "                earnings_df.insert(0, 'symbol', symbol)\n",
    "                earnings_df.rename(columns={'Earnings Date': 'release_date'}, inplace=True)\n",
    "                all_earnings_dates.append(earnings_df)\n",
    "        except Exception:\n",
    "            pass  # Some tickers may not have earnings dates\n",
    "        \n",
    "        # Add symbol column and append to lists\n",
    "        if not income_stmt.empty:\n",
    "            income_df = income_stmt.T.reset_index()\n",
    "            income_df.insert(0, 'symbol', symbol)\n",
    "            income_df.rename(columns={'index': 'fiscal_period_end'}, inplace=True)\n",
    "            all_income_stmt.append(income_df)\n",
    "        \n",
    "        if not balance_sheet.empty:\n",
    "            balance_df = balance_sheet.T.reset_index()\n",
    "            balance_df.insert(0, 'symbol', symbol)\n",
    "            balance_df.rename(columns={'index': 'fiscal_period_end'}, inplace=True)\n",
    "            all_balance_sheet.append(balance_df)\n",
    "        \n",
    "        if not cashflow.empty:\n",
    "            cashflow_df = cashflow.T.reset_index()\n",
    "            cashflow_df.insert(0, 'symbol', symbol)\n",
    "            cashflow_df.rename(columns={'index': 'fiscal_period_end'}, inplace=True)\n",
    "            all_cashflow.append(cashflow_df)\n",
    "        \n",
    "        # Progress update every 50 symbols\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Progress: {i + 1}/{len(symbols)} symbols fetched...\")\n",
    "        \n",
    "        # Small delay to avoid rate limiting\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        failed_financials.append(symbol)\n",
    "        if (i + 1) % 100 == 0:  # Only print errors occasionally to reduce noise\n",
    "            print(f\"  ✗ Error fetching {symbol}: {e}\")\n",
    "\n",
    "# Combine all DataFrames\n",
    "income_stmt_df = pd.concat(all_income_stmt, ignore_index=True) if all_income_stmt else pd.DataFrame()\n",
    "balance_sheet_df = pd.concat(all_balance_sheet, ignore_index=True) if all_balance_sheet else pd.DataFrame()\n",
    "cashflow_df = pd.concat(all_cashflow, ignore_index=True) if all_cashflow else pd.DataFrame()\n",
    "earnings_dates_df = pd.concat(all_earnings_dates, ignore_index=True) if all_earnings_dates else pd.DataFrame()\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"✓ Income Statement: {len(income_stmt_df)} rows, {income_stmt_df['symbol'].nunique() if not income_stmt_df.empty else 0} stocks\")\n",
    "print(f\"✓ Balance Sheet: {len(balance_sheet_df)} rows, {balance_sheet_df['symbol'].nunique() if not balance_sheet_df.empty else 0} stocks\")\n",
    "print(f\"✓ Cash Flow: {len(cashflow_df)} rows, {cashflow_df['symbol'].nunique() if not cashflow_df.empty else 0} stocks\")\n",
    "print(f\"✓ Earnings Dates: {len(earnings_dates_df)} rows, {earnings_dates_df['symbol'].nunique() if not earnings_dates_df.empty else 0} stocks\")\n",
    "if failed_financials:\n",
    "    print(f\"✗ Failed: {len(failed_financials)} symbols\")\n",
    "\n",
    "print(\"\\nEarnings Release Dates preview:\")\n",
    "display(earnings_dates_df.head(10))\n",
    "\n",
    "print(\"\\nIncome Statement preview:\")\n",
    "display(income_stmt_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd0b782f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Income Statement saved to income_statement.csv (2.23 MB)\n",
      "✓ Balance Sheet saved to balance_sheet.csv (3.48 MB)\n",
      "✓ Cash Flow saved to cashflow.csv (2.71 MB)\n",
      "✓ Earnings Dates saved to earnings_dates.csv (1.03 MB)\n",
      "\n",
      "==================================================\n",
      "All financial data exported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save all financial DataFrames to CSV files\n",
    "import os\n",
    "\n",
    "# Save Income Statement\n",
    "income_stmt_df.to_csv(\"income_statement.csv\", index=False)\n",
    "print(f\"✓ Income Statement saved to income_statement.csv ({os.path.getsize('income_statement.csv') / (1024*1024):.2f} MB)\")\n",
    "\n",
    "# Save Balance Sheet\n",
    "balance_sheet_df.to_csv(\"balance_sheet.csv\", index=False)\n",
    "print(f\"✓ Balance Sheet saved to balance_sheet.csv ({os.path.getsize('balance_sheet.csv') / (1024*1024):.2f} MB)\")\n",
    "\n",
    "# Save Cash Flow\n",
    "cashflow_df.to_csv(\"cashflow.csv\", index=False)\n",
    "print(f\"✓ Cash Flow saved to cashflow.csv ({os.path.getsize('cashflow.csv') / (1024*1024):.2f} MB)\")\n",
    "\n",
    "# Save Earnings Dates\n",
    "earnings_dates_df.to_csv(\"earnings_dates.csv\", index=False)\n",
    "print(f\"✓ Earnings Dates saved to earnings_dates.csv ({os.path.getsize('earnings_dates.csv') / (1024*1024):.2f} MB)\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"All financial data exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9844a98",
   "metadata": {},
   "source": [
    "# Import historical News Data From Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d3d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news for 1019 symbols...\n",
      "Date range: 2025-01-08 to 2026-01-08\n",
      "\n",
      "  ✗ Error fetching news for A: 'tuple' object has no attribute 'id'\n",
      "  ✗ Error fetching news for AA: 'tuple' object has no attribute 'id'\n",
      "  ✗ Error fetching news for AAL: 'tuple' object has no attribute 'id'\n",
      "  ✗ Error fetching news for A: 'tuple' object has no attribute 'id'\n",
      "  ✗ Error fetching news for AA: 'tuple' object has no attribute 'id'\n",
      "  ✗ Error fetching news for AAL: 'tuple' object has no attribute 'id'\n",
      "  ✗ Error fetching news for AAON: 'tuple' object has no attribute 'id'\n",
      "  ✗ Error fetching news for AAPL: 'tuple' object has no attribute 'id'\n",
      "  ✗ Error fetching news for AAON: 'tuple' object has no attribute 'id'\n",
      "  ✗ Error fetching news for AAPL: 'tuple' object has no attribute 'id'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/stock_market_preds_v1/.venv/lib/python3.13/site-packages/alpaca/common/rest.py:198\u001b[39m, in \u001b[36mRESTClient._one_request\u001b[39m\u001b[34m(self, method, url, opts, retry)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[32m    200\u001b[39m     \u001b[38;5;66;03m# retry if we hit Rate Limit\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/stock_market_preds_v1/.venv/lib/python3.13/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 429 Client Error: Too Many Requests for url: https://data.alpaca.markets/v1beta1/news?start=2025-01-08T05%3A43%3A23.852459%2B00%3A00&end=2026-01-08T05%3A43%3A23.852459%2B00%3A00&symbols=SLB&limit=50&include_content=False&exclude_contentless=True",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRetryException\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/stock_market_preds_v1/.venv/lib/python3.13/site-packages/alpaca/common/rest.py:131\u001b[39m, in \u001b[36mRESTClient._request\u001b[39m\u001b[34m(self, method, path, data, base_url, api_version)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RetryException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/stock_market_preds_v1/.venv/lib/python3.13/site-packages/alpaca/common/rest.py:202\u001b[39m, in \u001b[36mRESTClient._one_request\u001b[39m\u001b[34m(self, method, url, opts, retry)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry_codes \u001b[38;5;129;01mand\u001b[39;00m retry > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RetryException()\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# raise API error for all other errors\u001b[39;00m\n",
      "\u001b[31mRetryException\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m# Create news request for this symbol\u001b[39;00m\n\u001b[32m     34\u001b[39m     request_params = NewsRequest(\n\u001b[32m     35\u001b[39m         symbols=symbol,\n\u001b[32m     36\u001b[39m         start=start_date,\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m         exclude_contentless=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     41\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     news_set = \u001b[43mnews_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_news\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     \u001b[38;5;66;03m# NewsSet is iterable - iterate directly over it\u001b[39;00m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m news_set:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/stock_market_preds_v1/.venv/lib/python3.13/site-packages/alpaca/data/historical/news.py:54\u001b[39m, in \u001b[36mNewsClient.get_news\u001b[39m\u001b[34m(self, request_params)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_news\u001b[39m(\u001b[38;5;28mself\u001b[39m, request_params: NewsRequest) -> Union[RawData, NewsSet]:\n\u001b[32m     50\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns news data\u001b[39;00m\n\u001b[32m     51\u001b[39m \n\u001b[32m     52\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03m        request_params (NewsRequest): The request params to filter the news data\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     raw_news = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_marketdata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/news\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_request_fields\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpage_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._use_raw_data:\n\u001b[32m     61\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m raw_news\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/stock_market_preds_v1/.venv/lib/python3.13/site-packages/alpaca/common/rest.py:393\u001b[39m, in \u001b[36mRESTClient._get_marketdata\u001b[39m\u001b[34m(self, path, params, page_limit, page_size, no_sub_key)\u001b[39m\n\u001b[32m    390\u001b[39m params[\u001b[33m\"\u001b[39m\u001b[33mlimit\u001b[39m\u001b[33m\"\u001b[39m] = actual_limit\n\u001b[32m    391\u001b[39m params[\u001b[33m\"\u001b[39m\u001b[33mpage_token\u001b[39m\u001b[33m\"\u001b[39m] = page_token\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _get_marketdata_entries(response, no_sub_key).items():\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/stock_market_preds_v1/.venv/lib/python3.13/site-packages/alpaca/common/rest.py:225\u001b[39m, in \u001b[36mRESTClient.get\u001b[39m\u001b[34m(self, path, data, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\n\u001b[32m    213\u001b[39m     \u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m, data: Optional[Union[\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs\n\u001b[32m    214\u001b[39m ) -> HTTPResult:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Performs a single GET request\u001b[39;00m\n\u001b[32m    216\u001b[39m \n\u001b[32m    217\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    223\u001b[39m \u001b[33;03m        dict: The response\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/stock_market_preds_v1/.venv/lib/python3.13/site-packages/alpaca/common/rest.py:133\u001b[39m, in \u001b[36mRESTClient._request\u001b[39m\u001b[34m(self, method, path, data, base_url, api_version)\u001b[39m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._one_request(method, url, opts, retry)\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RetryException:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_wait\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m     retry -= \u001b[32m1\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Fetch Alpaca news data for all tickers\n",
    "from alpaca.data.historical import NewsClient\n",
    "from alpaca.data.requests import NewsRequest\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Load tickers\n",
    "tickers_df = pd.read_csv(\"tickers.csv\")\n",
    "symbols = tickers_df['symbol'].tolist()\n",
    "\n",
    "# Initialize news client\n",
    "news_client = NewsClient(API_KEY, SECRET_KEY)\n",
    "\n",
    "# Date range for last year\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=365)\n",
    "\n",
    "# List to store all news articles\n",
    "all_news = []\n",
    "failed_news = []\n",
    "\n",
    "print(f\"Fetching news for {len(symbols)} symbols...\")\n",
    "print(f\"Date range: {start_date.date()} to {end_date.date()}\\n\")\n",
    "\n",
    "# Fetch news one symbol at a time\n",
    "for i, symbol in enumerate(symbols):\n",
    "    try:\n",
    "        # Create news request for this symbol\n",
    "        request_params = NewsRequest(\n",
    "            symbols=symbol,\n",
    "            start=start_date,\n",
    "            end=end_date,\n",
    "            limit=50,\n",
    "            include_content=False,\n",
    "            exclude_contentless=True\n",
    "        )\n",
    "        \n",
    "        news_set = news_client.get_news(request_params)\n",
    "        \n",
    "        # NewsSet is iterable - iterate directly over it\n",
    "        for article in news_set:\n",
    "            article_dict = {\n",
    "                'id': article.id,\n",
    "                'headline': article.headline,\n",
    "                'summary': article.summary,\n",
    "                'author': article.author,\n",
    "                'created_at': article.created_at,\n",
    "                'updated_at': article.updated_at,\n",
    "                'url': article.url,\n",
    "                'symbols': ','.join(article.symbols) if article.symbols else '',\n",
    "                'source': article.source\n",
    "            }\n",
    "            all_news.append(article_dict)\n",
    "        \n",
    "        # Progress update every 100 symbols\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Progress: {i + 1}/{len(symbols)} symbols processed, {len(all_news)} articles collected...\")\n",
    "        \n",
    "        # Small delay to avoid rate limiting\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        failed_news.append(symbol)\n",
    "        # Only print first few errors\n",
    "        if len(failed_news) <= 5:\n",
    "            print(f\"  ✗ Error fetching news for {symbol}: {e}\")\n",
    "\n",
    "# Create DataFrame\n",
    "news_df = pd.DataFrame(all_news)\n",
    "\n",
    "# Remove duplicates (same article may appear for multiple symbols)\n",
    "if not news_df.empty:\n",
    "    news_df = news_df.drop_duplicates(subset=['id'])\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"✓ Total unique news articles: {len(news_df)}\")\n",
    "if failed_news:\n",
    "    print(f\"✗ Failed: {len(failed_news)} symbols\")\n",
    "\n",
    "if not news_df.empty:\n",
    "    print(f\"\\nNews DataFrame preview:\")\n",
    "    display(news_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff2fdd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response type: <class 'alpaca.data.models.news.NewsSet'>\n",
      "Response attributes: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_on_complete__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'copy', 'data', 'df', 'dict', 'from_orm', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'next_page_token', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'update_forward_refs', 'validate']\n",
      "\n",
      "Response content:\n",
      "data={'news': [{   'author': 'Benzinga Newsdesk',\n",
      "    'content': '',\n",
      "    'created_at': datetime.datetime(2026, 1, 7, 18, 3, 51, tzinfo=TzInfo(0)),\n",
      "    'headline': \"'Anthropic Raising $10 Billion at $350 Billion Value'- WSJ\",\n",
      "    'id': 49763077,\n",
      "    'images': [],\n",
      "    'source': 'benzinga',\n",
      "    'summary': '',\n",
      "    'symbols': ['AMZN', 'GOOG', 'GOOGL'],\n",
      "    'updated_at': datetime.datetime(2026, 1, 7, 18, 3, 52, tzinfo=TzInfo(0)),\n",
      "    'url': 'https://www.benzinga.com/news/26/01/49763077/anthropic-raising-10-billion-at-350-billion-value-wsj'}, {   'author': 'Benzinga Insights',\n",
      "    'content': '',\n",
      "    'created_at': datetime.datetime(2026, 1, 7, 17, 35, 20, tzinfo=TzInfo(0)),\n",
      "    'headline': \"10 Consumer Discretionary Stocks Whale Activity In Today's \"\n",
      "                'Session',\n",
      "    'id': 49761851,\n",
      "    'images': [   {   'size': <NewsImageSize.LARGE: 'large'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2025/11/06/aggregated_options_3.jpg?width=2048&height=1536'},\n",
      "                  {   'size': <NewsImageSize.SMALL: 'small'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2025/11/06/aggregated_options_3.jpg?width=1024&height=768'},\n",
      "                  {   'size': <NewsImageSize.THUMB: 'thumb'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2025/11/06/aggregated_options_3.jpg?width=250&height=187'}],\n",
      "    'source': 'benzinga',\n",
      "    'summary': ' ',\n",
      "    'symbols': [   'AMZN',\n",
      "                   'CAVA',\n",
      "                   'CMG',\n",
      "                   'CVNA',\n",
      "                   'DASH',\n",
      "                   'LVS',\n",
      "                   'MCD',\n",
      "                   'RIVN',\n",
      "                   'SBUX',\n",
      "                   'TSLA'],\n",
      "    'updated_at': datetime.datetime(2026, 1, 7, 17, 35, 21, tzinfo=TzInfo(0)),\n",
      "    'url': 'https://www.benzinga.com/insights/options/26/01/49761851/10-consumer-discretionary-stocks-whale-activity-in-todays-session'}, {   'author': 'The Arora Report',\n",
      "    'content': '',\n",
      "    'created_at': datetime.datetime(2026, 1, 7, 17, 24, 16, tzinfo=TzInfo(0)),\n",
      "    'headline': 'Nvidia Triggers Mania In Micron And SanDisk; Momo Loses in '\n",
      "                \"Chevron Euphoria; Supreme Court's Tariff Decision Ahead\",\n",
      "    'id': 49761479,\n",
      "    'images': [],\n",
      "    'source': 'benzinga',\n",
      "    'summary': '\\n\\n\\n\\nNAND Mania\\n\\n\\n',\n",
      "    'symbols': [   'AAPL',\n",
      "                   'ADP',\n",
      "                   'AMZN',\n",
      "                   'BTCUSD',\n",
      "                   'CVX',\n",
      "                   'GOOG',\n",
      "                   'META',\n",
      "                   'MSFT',\n",
      "                   'MU',\n",
      "                   'NVDA',\n",
      "                   'QQQ',\n",
      "                   'SNDK',\n",
      "                   'SPY',\n",
      "                   'STX',\n",
      "                   'TSLA',\n",
      "                   'WDC'],\n",
      "    'updated_at': datetime.datetime(2026, 1, 7, 17, 25, 56, tzinfo=TzInfo(0)),\n",
      "    'url': 'https://www.benzinga.com/Opinion/26/01/49761479/nvidia-triggers-mania-in-micron-and-sandisk-momo-loses-in-chevron-euphoria-supreme-courts-tariff-decision-ahead'}, {   'author': 'Gav Blaxberg',\n",
      "    'content': '',\n",
      "    'created_at': datetime.datetime(2026, 1, 7, 14, 58, 3, tzinfo=TzInfo(0)),\n",
      "    'headline': 'Robotics Is A Margin Story: The Mispriced Robotics Narrative',\n",
      "    'id': 49755302,\n",
      "    'images': [   {   'size': <NewsImageSize.LARGE: 'large'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/Gav-Blaxberg.jpeg?width=2048&height=1536'},\n",
      "                  {   'size': <NewsImageSize.SMALL: 'small'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/Gav-Blaxberg.jpeg?width=1024&height=768'},\n",
      "                  {   'size': <NewsImageSize.THUMB: 'thumb'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/Gav-Blaxberg.jpeg?width=250&height=187'}],\n",
      "    'source': 'benzinga',\n",
      "    'summary': ' ',\n",
      "    'symbols': ['AMD', 'AMZN', 'MELI', 'NVDA'],\n",
      "    'updated_at': datetime.datetime(2026, 1, 7, 14, 58, 3, tzinfo=TzInfo(0)),\n",
      "    'url': 'https://www.benzinga.com/Opinion/26/01/49755302/robotics-is-a-margin-story-the-mispriced-robotics-narrative'}, {   'author': 'Namrata Sen',\n",
      "    'content': '',\n",
      "    'created_at': datetime.datetime(2026, 1, 7, 13, 36, 26, tzinfo=TzInfo(0)),\n",
      "    'headline': 'Goldman Sachs Predicts Tough Road Ahead For Stocks, But No '\n",
      "                'Repeat Of 1920s Or 1987',\n",
      "    'id': 49751779,\n",
      "    'images': [   {   'size': <NewsImageSize.LARGE: 'large'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/A-Magnifying-Glass-Over-A-Financial-Char.jpeg?width=2048&height=1536'},\n",
      "                  {   'size': <NewsImageSize.SMALL: 'small'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/A-Magnifying-Glass-Over-A-Financial-Char.jpeg?width=1024&height=768'},\n",
      "                  {   'size': <NewsImageSize.THUMB: 'thumb'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/A-Magnifying-Glass-Over-A-Financial-Char.jpeg?width=250&height=187'}],\n",
      "    'source': 'benzinga',\n",
      "    'summary': 'Goldman Sachs Group Inc.\\xa0strategists have issued a warning '\n",
      "               'about the challenging path ahead for the U.S. stock market. '\n",
      "               'However, they believe that the current market situation will '\n",
      "               'not mirror the crashes of the 1920s or 1987.',\n",
      "    'symbols': ['AMZN', 'GOOG', 'GOOGL', 'META', 'MSFT', 'QQQ', 'VOO'],\n",
      "    'updated_at': datetime.datetime(2026, 1, 7, 13, 36, 27, tzinfo=TzInfo(0)),\n",
      "    'url': 'https://www.benzinga.com/markets/equities/26/01/49751779/goldman-sachs-predicts-tough-road-ahead-for-stocks-but-no-repeat-of-1920s-or-1987'}, {   'author': 'Avi Kapoor',\n",
      "    'content': '',\n",
      "    'created_at': datetime.datetime(2026, 1, 7, 13, 1, 18, tzinfo=TzInfo(0)),\n",
      "    'headline': \"Uber, Amazon, Affiliated Managers Group And More On CNBC's \"\n",
      "                \"'Final Trades'\",\n",
      "    'id': 49750558,\n",
      "    'images': [   {   'size': <NewsImageSize.LARGE: 'large'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/Two-Diverse-Crypto-Traders-Brokers-Stock_0.jpeg?width=2048&height=1536'},\n",
      "                  {   'size': <NewsImageSize.SMALL: 'small'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/Two-Diverse-Crypto-Traders-Brokers-Stock_0.jpeg?width=1024&height=768'},\n",
      "                  {   'size': <NewsImageSize.THUMB: 'thumb'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/Two-Diverse-Crypto-Traders-Brokers-Stock_0.jpeg?width=250&height=187'}],\n",
      "    'source': 'benzinga',\n",
      "    'summary': 'Joshua Brown chose Amazon (AMZN) and Brian Belski selected '\n",
      "               'Affiliated Managers Group (AMG) as their final trades, '\n",
      "               'supported by analysts&#39; positive views on the companies.',\n",
      "    'symbols': ['AMG', 'AMZN', 'IYC', 'TMOAF', 'UBER'],\n",
      "    'updated_at': datetime.datetime(2026, 1, 7, 13, 1, 18, tzinfo=TzInfo(0)),\n",
      "    'url': 'https://www.benzinga.com/trading-ideas/long-ideas/26/01/49750558/uber-amazon-affiliated-managers-group-and-more-on-cnbcs-final-trades'}, {   'author': 'Lekha Gupta',\n",
      "    'content': '',\n",
      "    'created_at': datetime.datetime(2026, 1, 7, 12, 15, 14, tzinfo=TzInfo(0)),\n",
      "    'headline': 'Infosys, AWS Team Up To Speed Enterprise Generative AI '\n",
      "                'Adoption',\n",
      "    'id': 49749116,\n",
      "    'images': [   {   'size': <NewsImageSize.LARGE: 'large'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/Infosys-Photo-by-Jonathan-Weiss-via-Shut.jpeg?width=2048&height=1536'},\n",
      "                  {   'size': <NewsImageSize.SMALL: 'small'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/Infosys-Photo-by-Jonathan-Weiss-via-Shut.jpeg?width=1024&height=768'},\n",
      "                  {   'size': <NewsImageSize.THUMB: 'thumb'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/Infosys-Photo-by-Jonathan-Weiss-via-Shut.jpeg?width=250&height=187'}],\n",
      "    'source': 'benzinga',\n",
      "    'summary': 'Infosys partners with AWS to accelerate enterprise adoption of '\n",
      "               'generative AI, also collaborates with Cognition.',\n",
      "    'symbols': ['AMZN', 'INFY'],\n",
      "    'updated_at': datetime.datetime(2026, 1, 7, 12, 15, 15, tzinfo=TzInfo(0)),\n",
      "    'url': 'https://www.benzinga.com/markets/tech/26/01/49749116/infosys-aws-team-up-to-speed-enterprise-generative-ai-adoption'}, {   'author': 'Snigdha Gairola',\n",
      "    'content': '',\n",
      "    'created_at': datetime.datetime(2026, 1, 7, 10, 36, 45, tzinfo=TzInfo(0)),\n",
      "    'headline': 'Gwyneth Paltrow Says Turning 40 Taught Her to Stop '\n",
      "                \"People-Pleasing, Start Speaking Her Truth: 'It's So \"\n",
      "                \"Self-Honoring…'\",\n",
      "    'id': 49747050,\n",
      "    'images': [   {   'size': <NewsImageSize.LARGE: 'large'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/Gwyneth-Paltrow-arrives-for-the-2019-amF.jpeg?width=2048&height=1536'},\n",
      "                  {   'size': <NewsImageSize.SMALL: 'small'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/Gwyneth-Paltrow-arrives-for-the-2019-amF.jpeg?width=1024&height=768'},\n",
      "                  {   'size': <NewsImageSize.THUMB: 'thumb'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2026/01/07/Gwyneth-Paltrow-arrives-for-the-2019-amF.jpeg?width=250&height=187'}],\n",
      "    'source': 'benzinga',\n",
      "    'summary': 'Gwyneth Paltrow discusses her struggle with people-pleasing '\n",
      "               'and prioritizing others&#39; approval over her own voice.',\n",
      "    'symbols': ['AMZN', 'BABA', 'BAC', 'JPM'],\n",
      "    'updated_at': datetime.datetime(2026, 1, 7, 10, 37, 5, tzinfo=TzInfo(0)),\n",
      "    'url': 'https://www.benzinga.com/news/entertainment/26/01/49747050/gwyneth-paltrow-says-turning-40-taught-her-to-stop-people-pleasing-start-speaking-her-truth-its-so-self-honoring'}, {   'author': 'Benzinga Newsdesk',\n",
      "    'content': '',\n",
      "    'created_at': datetime.datetime(2026, 1, 7, 6, 23, 7, tzinfo=TzInfo(0)),\n",
      "    'headline': 'Infosys Expands Strategic Collaboration With AWS To '\n",
      "                'Accelerate Generative AI Adoption And Transform Enterprise '\n",
      "                'Operations And Client Outcomes Globally',\n",
      "    'id': 49745143,\n",
      "    'images': [],\n",
      "    'source': 'benzinga',\n",
      "    'summary': '',\n",
      "    'symbols': ['AMZN', 'INFY'],\n",
      "    'updated_at': datetime.datetime(2026, 1, 7, 6, 23, 8, tzinfo=TzInfo(0)),\n",
      "    'url': 'https://www.benzinga.com/news/26/01/49745143/infosys-expands-strategic-collaboration-with-aws-to-accelerate-generative-ai-adoption-and-transform'}, {   'author': 'Benzinga Insights',\n",
      "    'content': '',\n",
      "    'created_at': datetime.datetime(2026, 1, 6, 18, 1, 55, tzinfo=TzInfo(0)),\n",
      "    'headline': 'Market Whales and Their Recent Bets on AMZN Options',\n",
      "    'id': 49733461,\n",
      "    'images': [   {   'size': <NewsImageSize.LARGE: 'large'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2025/11/06/movers_2.jpg?width=2048&height=1536'},\n",
      "                  {   'size': <NewsImageSize.SMALL: 'small'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2025/11/06/movers_2.jpg?width=1024&height=768'},\n",
      "                  {   'size': <NewsImageSize.THUMB: 'thumb'>,\n",
      "                      'url': 'https://cdn.benzinga.com/files/images/story/2025/11/06/movers_2.jpg?width=250&height=187'}],\n",
      "    'source': 'benzinga',\n",
      "    'summary': ' ',\n",
      "    'symbols': ['AMZN'],\n",
      "    'updated_at': datetime.datetime(2026, 1, 6, 18, 1, 56, tzinfo=TzInfo(0)),\n",
      "    'url': 'https://www.benzinga.com/insights/options/26/01/49733461/market-whales-and-their-recent-bets-on-amzn-options'}]} next_page_token=None\n"
     ]
    }
   ],
   "source": [
    "# Test Alpaca news API with just AMZN\n",
    "from alpaca.data.historical import NewsClient\n",
    "from alpaca.data.requests import NewsRequest\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "API_KEY = \"PKRCRKMGTONEXYW5GZKOYXSGZI\"\n",
    "SECRET_KEY = \"APCFooZAsKWCFvvkNQSdLwpoNHfyhtwdRajBQrEdJuku\"\n",
    "\n",
    "news_client = NewsClient(API_KEY, SECRET_KEY)\n",
    "\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=30)  # Just last 30 days for testing\n",
    "\n",
    "request_params = NewsRequest(\n",
    "    symbols=\"AMZN\",\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    limit=10\n",
    ")\n",
    "\n",
    "news_response = news_client.get_news(request_params)\n",
    "\n",
    "# Debug: Check what type and attributes the response has\n",
    "print(f\"Response type: {type(news_response)}\")\n",
    "print(f\"Response attributes: {dir(news_response)}\")\n",
    "print(f\"\\nResponse content:\")\n",
    "print(news_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
